{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load a model\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import yaml\n",
    "import torch\n",
    "# from coconut.coconut import Coconut\n",
    "from coconut.utils import Config, set_seed, ProgressCallbackNoPrint, rm_old_prog_cb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coconut.coconut import (\n",
    "    CoconutConfig,\n",
    "    CoconutQwen2ForCausalLM,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "f = \"../outputs/gsm-qwen_20250201-122443/checkpoint_3\"\n",
    "fc = f + '/config.yaml'\n",
    "with open(fc) as f2:\n",
    "    config_dict = yaml.safe_load(f2)\n",
    "configs = Config(config_dict)\n",
    "\n",
    "model = CoconutQwen2ForCausalLM.from_pretrained(f, device_map=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(f)\n",
    "# model.load_state_dict(safe_open(f1, 'pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46477327b3024f79ae3cca6a894813a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "../data/gsm_valid.json (num_proc=32):   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8176d36ee9f44551827348834002bdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "q_latent_3 (num_proc=32):   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from coconut.dataset import (\n",
    "    CoconutCollator,\n",
    "    get_cot_latent_dataset,\n",
    "    get_dataset,\n",
    "    get_question_only_latent_dataset,\n",
    ")\n",
    "from coconut.eval import evaluate\n",
    "\n",
    "bot_id = tokenizer.convert_tokens_to_ids(\"<|start-latent|>\")\n",
    "eot_id = tokenizer.convert_tokens_to_ids(\"<|end-latent|>\")\n",
    "scheduled_stage = 3\n",
    "latent_id = tokenizer.convert_tokens_to_ids(\"<|latent|>\")\n",
    "\n",
    "max_size = 1024\n",
    "base_dataset_valid = get_dataset(\n",
    "    '../' + configs.val_path, tokenizer, max_size=max_size//30+3, drop_unused=False\n",
    ")\n",
    "\n",
    "dataset_gen_val = get_question_only_latent_dataset(\n",
    "    scheduled_stage,\n",
    "    base_dataset_valid,\n",
    "    configs,\n",
    "    bot_id,\n",
    "    latent_id,\n",
    "    eot_id,\n",
    "    no_bot_eot=False,\n",
    "    # drop_unused=False,\n",
    ")\n",
    "collator = CoconutCollator(tokenizer, latent_id=latent_id, label_pad_token_id=-100)\n",
    "valid_gen_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_gen_val,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    batch_size=6,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "\n",
    "# run eval\n",
    "max_new_tokens = 64\n",
    "device = \"cuda\"\n",
    "dtype = torch.bfloat16\n",
    "phase = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62db594129b54fc4a22a1977df6484a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Accuracy eval_-1:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-01 15:49:09.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mStarting evaluation eval_-1\u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:09.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #0: Answer = '300' ideal_CoT = '<<4-2=2>>\n",
      "\t<<2/.5=4>>\n",
      "\t<<12/4=3>>\n",
      "\t<<100*3=300>>,'.\n",
      "    Question: `John cuts his grass to 2 inches.  It grows .5 inches per month.  When it gets to 4 inches he cuts it back down to 2 inches.  It cost $100 to get his grass cut.  How much does he pay per year?`.\n",
      "    Extracted llm Output: `John cuts his grass to 2 inche...` (=? 300) ❌.\n",
      "    Full llm output: `John cuts his grass to 2 inche...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:09.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #1: Answer = '10' ideal_CoT = '<<1.5*2=3>>\n",
      "\t<<3+2.5=5.5>>\n",
      "\t<<1.5+3+5.5=10>>,'.\n",
      "    Question: `Hannah has three dogs. The first dog eats 1.5 cups of dog food a day. The second dog eats twice as much while the third dog eats 2.5 cups more than the second dog. How many cups of dog food should Hannah prepare in a day for her three dogs?`.\n",
      "    Extracted llm Output: `30` (=? 10) ❌.\n",
      "    Full llm output: `Hannah has three dogs. The fir...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:09.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #2: Answer = '1400' ideal_CoT = '<<30/100*2000=600>>\n",
      "\t<<2000-600=1400>>,'.\n",
      "    Question: `Travis wants to fly to Australia. The regular tickets cost about $2000. As Travis is a student, he will get a 30% discount on this price. How much does he need to pay for his ticket?`.\n",
      "    Extracted llm Output: `140` (=? 1400) ❌.\n",
      "    Full llm output: `Travis wants to fly to Austral...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:09.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #3: Answer = '15' ideal_CoT = '<<21/7=3>>\n",
      "\t<<5*3=15>>,'.\n",
      "    Question: `A set of 7 spoons costs $21. If each spoon would be sold separately, how much would 5 spoons cost?`.\n",
      "    Extracted llm Output: `105` (=? 15) ❌.\n",
      "    Full llm output: `A set of 7 spoons costs $21. I...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:09.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #4: Answer = '240' ideal_CoT = '<<200*3=600>>\n",
      "\t<<600*.4=240>>,'.\n",
      "    Question: `Tom bought his games for $200.  They tripled in value and he then sold 40% of them.  How much did he sell the games for?`.\n",
      "    Extracted llm Output: `160` (=? 240) ❌.\n",
      "    Full llm output: `Tom bought his games for $200....`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:09.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #5: Answer = '20' ideal_CoT = '<<1/2*100=50>>\n",
      "\t<<3/5*50=30>>\n",
      "\t<<50-30=20>>,'.\n",
      "    Question: `Maggie went to Lou's aquarium and saw 100 goldfish in the aquarium. She asked if she could take some home to care for, and she was allowed to catch half of them. While using a catching net, she caught 3/5 of the total number of goldfish she was allowed to take home. How many goldfish does Maggie remain with to catch to get the total number she was allowed to take home?`.\n",
      "    Extracted llm Output: `16` (=? 20) ❌.\n",
      "    Full llm output: `Maggie went to Lou's aquarium ...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:10.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #6: Answer = '10' ideal_CoT = '<<40/2=20>>\n",
      "\t<<20/2=10>>,'.\n",
      "    Question: `Kenny played basketball last week. He ran for twice as long as he played basketball, and he practiced on the trumpet for twice as long as he ran. If he practiced on the trumpet for 40 hours, how many hours did Kenny play basketball last week?`.\n",
      "    Extracted llm Output: `16` (=? 10) ❌.\n",
      "    Full llm output: `Kenny played basketball last w...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:10.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #7: Answer = '2' ideal_CoT = '<<12*2=24>>\n",
      "\t<<4*1=4>>\n",
      "\t<<3*4=12>>\n",
      "\t<<24+4+12=40>>\n",
      "\t<<12+4+4=20>>\n",
      "\t<<40/20=2>>,'.\n",
      "    Question: `Marcia wants to buy some fruit. Apples cost $2, bananas cost $1, and oranges cost $3. If Marcia buys 12 apples, 4 bananas and 4 oranges, what is the average cost of each piece of fruit in dollars?`.\n",
      "    Extracted llm Output: `` (=? 2) ❌.\n",
      "    Full llm output: `Marcia wants to buy some fruit...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:10.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #8: Answer = '25' ideal_CoT = '<<2*2.25=4.50>>\n",
      "\t<<2*4=8.00>>\n",
      "\t<<2*2.50=5.00>>\n",
      "\t<<4.50+8.00+.50+5.00+3.50+3.50=25.00>>,'.\n",
      "    Question: `It’s Meghan’s turn to pick up her team's coffee order.  She needs 2 drip coffees that are $2.25 each and one double shot espresso that’s $3.50.  She needs 2 lattes that are $4.00 and needs to add vanilla syrup to one of those for an additional $0.50.  She also needs 2 cold brew coffees that are $2.50 each and 1 cappuccino for $3.50.  How much is the coffee order?`.\n",
      "    Extracted llm Output: `11.5` (=? 25) ❌.\n",
      "    Full llm output: `It’s Meghan’s turn to pick up ...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:10.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #9: Answer = '25' ideal_CoT = '<<32=32>>\n",
      "\t<<8=8>>,'.\n",
      "    Question: `Roman and Remy took separate showers. Remy used 1 more gallon than 3 times the number of gallons that Roman used for his shower. Together the boys used 33 gallons of water.  How many gallons did Remy use?`.\n",
      "    Extracted llm Output: `13` (=? 25) ❌.\n",
      "    Full llm output: `Roman and Remy took separate s...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:10.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #10: Answer = '4' ideal_CoT = '<<14/2=7>>\n",
      "\t<<15/3=5>>\n",
      "\t<<2*5=10>>\n",
      "\t<<14-10=4>>,'.\n",
      "    Question: `Lionel went to the grocery store and bought 14 boxes of Graham crackers and 15 packets of Oreos. To make an Oreo cheesecake, Lionel needs 2 boxes of Graham crackers and 3 packets of Oreos. After making the maximum number of Oreo cheesecakes he can with the ingredients he bought, how many boxes of Graham crackers would he have left over?`.\n",
      "    Extracted llm Output: `` (=? 4) ❌.\n",
      "    Full llm output: `Lionel went to the grocery sto...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:10.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mQ #11: Answer = '80' ideal_CoT = '<<98-43=55>>\n",
      "\t<<55+23=78>>\n",
      "\t<<73=73>>\n",
      "\t<<73+7=80>>,'.\n",
      "    Question: `When Suzy the librarian sat at her desk on Wednesday morning, she had 98 books ready for checkout. The same day, 43 books were checked out. The following day, 23 books were returned, but 5 books were checked out. On Friday, 7 books were returned. How many books did Suzy have?`.\n",
      "    Extracted llm Output: `12` (=? 80) ❌.\n",
      "    Full llm output: `When Suzy the librarian sat at...`. \n",
      "    \u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:12.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mCorrect=0, CoT_correct=0, Total=37. eval_-1\u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:12.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mAccuracy on val:  0 / 37 =  0.0000%\u001b[0m\n",
      "\u001b[32m2025-02-01 15:49:12.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcoconut.eval\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mCoT match on val: 0 / 37 =  0.0000%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "r = evaluate(valid_gen_dataloader, model, tokenizer, base_dataset_valid, max_new_tokens=max_new_tokens, name=f\"eval_{phase}\", dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
